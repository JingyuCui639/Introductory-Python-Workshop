{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Workshop Title: Intermediate Python Workshop: EDA, Statistical Testing and Introduction to Machine Learning**\n",
    "\n",
    "**Duration: 3 hours**\n",
    "\n",
    "**Objective**: To provide intermediate Python programmers with practical knowledge on Exploratory Data Analysis (EDA), statistical testing, and a brief introduction to machine learning.\n",
    "\n",
    "**Prerequisites**: Basic knowledge of Python programming and basic understanding of statistics.\n",
    "\n",
    "---\n",
    "\n",
    "### I. Introduction (15 minutes)\n",
    "\n",
    "- Brief Introduction to the Workshop Topics\n",
    "- Importance and Applications of EDA, Statistical Testing and Machine Learning\n",
    "\n",
    "---\n",
    "\n",
    "### II. Exploratory Data Analysis (EDA) with Python (45 minutes)\n",
    "\n",
    "**Key Concepts**: Pandas, Numpy, Matplotlib, Seaborn\n",
    "\n",
    "- Introduction to EDA\n",
    "- Python Libraries for EDA: Brief Overview\n",
    "- Data Cleaning:\n",
    "  - Handling Missing Data\n",
    "  - Removing Duplicates\n",
    "  - Data Type Conversion\n",
    "- Data Visualization:\n",
    "  - Histograms\n",
    "  - Box plots\n",
    "  - Scatter plots\n",
    "- Descriptive Statistics: Mean, Median, Mode, Skewness, Kurtosis\n",
    "\n",
    "---\n",
    "\n",
    "### III. Statistical Testing with Python (45 minutes)\n",
    "\n",
    "**Key Concepts**: Scipy, ANOVA, T-Test\n",
    "\n",
    "- Introduction to Statistical Testing\n",
    "- Hypothesis Testing Overview\n",
    "- T-Test:\n",
    "  - One-sample T-test\n",
    "  - Two-sample T-test\n",
    "- ANOVA:\n",
    "  - One-way ANOVA\n",
    "  - Two-way ANOVA\n",
    "- Interpretation of Results\n",
    "\n",
    "---\n",
    "\n",
    "### IV. Introduction to Machine Learning with Python (1 hour)\n",
    "**Key Concepts**: Scikit-learn, Supervised Learning, Unsupervised Learning\n",
    "\n",
    "- Introduction to Machine Learning\n",
    "- Types of Machine Learning: Supervised, Unsupervised, and Reinforcement Learning\n",
    "- Supervised Learning:\n",
    "  - Linear Regression: Brief Overview and Python Implementation\n",
    "  - Classification: Brief Overview and Python Implementation (e.g., Logistic Regression)\n",
    "- Unsupervised Learning:\n",
    "  - Clustering: Brief Overview and Python Implementation (e.g., K-means)\n",
    "- Introduction to Scikit-Learn Library\n",
    "- Data Splitting: Training Set and Test Set\n",
    "- Model Training and Prediction\n",
    "- Model Evaluation\n",
    "\n",
    "--- \n",
    "\n",
    "### V. Q&A and Closing Remarks (15 minutes)\n",
    "\n",
    "- Attendee Questions\n",
    "- Summary of the Workshop\n",
    "- Further Learning Resources"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section II: EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "# Display the first few rows\n",
    "print(df.head())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get some basic information about the data\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the numerical data description\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the categorical data description\n",
    "print(df.describe())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing age data with median age\n",
    "df['age'].fillna(df['age'].median(), inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing embarked data with the mode\n",
    "df['embarked'].fillna(df['embarked'].mode()[0], inplace=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Too many missing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'deck' column as it has too many missing values\n",
    "df = df.drop(['deck'], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing duplicates\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is just an example\n",
    "# Outlier Detection with IQR for 'age'\n",
    "Q1 = df['age'].quantile(0.25)\n",
    "Q3 = df['age'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Defining the acceptable range\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifying outliers\n",
    "outliers = df[(df['age'] < lower_bound) | (df['age'] > upper_bound)]\n",
    "print(outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing outliers\n",
    "df_out = df[(df['age'] >= lower_bound) & (df['age'] <= upper_bound)]\n",
    "# Note this is not going to change df, but generating a new df called df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing shapes of the original and cleaned dataframes\n",
    "print(df.shape)\n",
    "print(df_out.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting 'survived' from int to bool\n",
    "df['survived'] = df['survived'].astype(bool)\n",
    "print(df.info())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace with mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_sex = {'female': 1, 'male': 0}\n",
    "df['sex'] = df['sex'].map(map_sex)\n",
    "print(df.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visulization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the updated info\n",
    "print(df.info())\n",
    "\n",
    "# Checking the descriptive statistics\n",
    "print(df.describe())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograms for numerical columns\n",
    "df.hist(bins=30, figsize=(10,10))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BoxPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plot of age across different classes\n",
    "sns.boxplot(x='class', y='age', data=df)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bar Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot of survival by class\n",
    "sns.barplot(x='class', y='survived', data=df)\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pairplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairplot to visualize the relationships between variables\n",
    "sns.pairplot(df, hue='survived')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(df.corr(), annot=True, cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section III: Statistical Testing with Python (45 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-sample t-test\n",
    "\n",
    "The one-sample T-test is used when we want to compare a sample mean with a population mean. It helps us to understand if the sample taken from the population has the same mean or not. The scenario in the code is checking whether the mean age of passengers on the Titanic is 30 or not."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Null hypothesis (H0): The mean age of all passengers on the Titanic is 30.\n",
    "\n",
    "Alternative hypothesis (H1): The mean age of all passengers on the Titanic is not 30."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-sample T-test\n",
    "age = df_out['age']\n",
    "age_mean = np.mean(age)\n",
    "tset, pval = stats.ttest_1samp(age, 30)  # testing against mean age 30\n",
    "print('One-sample T-test p-value', pval)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two-sample T-test\n",
    "\n",
    "The two-sample T-test is used when we want to compare the means of two different samples. This test tells us if the two samples come from the same population or not. In the code, we're comparing the mean age of passengers in first class and third class to see if they're the same.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Null hypothesis (H0): The mean age of passengers in first class is equal to the mean age of passengers in third class.\n",
    "\n",
    "Alternative hypothesis (H1): The mean age of passengers in first class is not equal to the mean age of passengers in third class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_class_1 = df_out[df_out['class'] == 'First']['age']\n",
    "age_class_3 = df_out[df_out['class'] == 'Third']['age']\n",
    "ttest, pval = stats.ttest_ind(age_class_1, age_class_3)\n",
    "print('Two-sample T-test p-value', pval)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paired T-test\n",
    "\n",
    "The paired T-test is used when we want to compare the means of the same group at two different times. For example, this could be used to compare a person's weight before and after a certain treatment. In the code, we're comparing the mean age of the first 50 passengers at two different time points (though we've simulated this with an increment of 1 for simplicity)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Null hypothesis (H0): The mean age of the first 50 passengers at time1 (before) is equal to their mean age at time2 (after).\n",
    "\n",
    "Alternative hypothesis (H1): The mean age of the first 50 passengers at time1 (before) is not equal to their mean age at time2 (after)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_before = df_out['age'].iloc[:50]\n",
    "age_after = df_out['age'].iloc[:50] + 1\n",
    "paired_ttest, pval = stats.ttest_rel(age_before, age_after)\n",
    "print('Paired T-test p-value', pval)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-way ANOVA\n",
    "The one-way analysis of variance (ANOVA) is used when we want to compare the means of more than two groups. It tells us if at least one group is significantly different from the others. In the code, we're comparing the mean ages of passengers in first, second, and third classes."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Null hypothesis (H0): The mean ages of passengers in first, second, and third classes are all equal.\n",
    "\n",
    "Alternative hypothesis (H1): At least one class has a different mean age compared to the others.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fstat, pval = stats.f_oneway(df_out[df_out['class'] == 'First']['age'], \n",
    "                             df_out[df_out['class'] == 'Second']['age'], \n",
    "                             df_out[df_out['class'] == 'Third']['age'])\n",
    "print('One-way ANOVA p-value', pval)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chi-square Test for Independence\n",
    "\n",
    "The chi-square test for independence is used when we want to see if there is a relationship between two categorical variables. In other words, it tests whether the occurrence of one categorical variable affects the occurrence of another categorical variable. In the code, we're checking if the 'survived' variable is related to the 'sex' variable."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Null hypothesis (H0): The 'survived' and 'sex' variables are independent, i.e., survival rate is the same for males and females.\n",
    "\n",
    "Alternative hypothesis (H1): The 'survived' and 'sex' variables are not independent, i.e., survival rate is not the same for males and females.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we check if 'survived' is related to 'sex'\n",
    "contingency_table = pd.crosstab(df_out['survived'], df_out['sex'])\n",
    "chi2, pval, dof, expected = stats.chi2_contingency(contingency_table)\n",
    "print('Chi-square p-value', pval)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section IV: Introduction to Machine Learning with Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Xs and Y:\n",
    "\n",
    "- We'll predict 'survived' based on 'pclass', 'sex', 'age', 'sibsp', 'parch'\n",
    "\n",
    "- This is supervised question"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing the dataset by selecting relevant features and the target variable. In this case, we're trying to predict 'survived' based on 'pclass', 'sex', 'age', 'sibsp', 'parch'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_out[['pclass', 'sex', 'age', 'sibsp', 'parch']]\n",
    "y = df_out['survived']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the data into training and test sets. This allows us to train our models on one set of data and then test them on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardizing the features. Many machine learning algorithms perform better when numerical input variables are scaled to a standard range. This includes algorithms that use a weighted sum of the input, like logistic regression, and algorithms that use distance measures, like k-nearest neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training and evaluating three different types of models: Logistic Regression, Random Forest, and Gradient Boosting. Each model is trained on the training data and then used to make predictions on the test data. The models' performance is evaluated using the classification report, which provides key metrics such as precision, recall, and f1-score."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "print(\"Logistic Regression:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "print(\"Random Forest:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GradientBoostingClassifier()\n",
    "gb.fit(X_train, y_train)\n",
    "y_pred = gb.predict(X_test)\n",
    "print(\"Gradient Boosting:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Report"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assume we have the following confusion matrix for a binary classification problem:\n",
    "\n",
    "|   | Predicted: No  | Predicted: Yes |\n",
    "|---|----------------|----------------|\n",
    "| Actual: No  | TN = 50  | FP = 10 |\n",
    "| Actual: Yes | FN = 5   | TP = 100|"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy:\n",
    "\n",
    "**Accuracy** Accuracy is the ratio of correctly predicted observations (TP + TN) to the total observations (TP + TN + FP + FN).\n",
    "\n",
    "Accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "\n",
    "= (100 + 50) / (100 + 50 + 10 + 5) = 0.91"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision: \n",
    "\n",
    "**Precision** is the ratio of correctly predicted positive (TP) observations to the total predicted positives (TP + FP). High precision relates to the low false positive rate. It is defined as:\n",
    "\n",
    "Precision = True Positives / (True Positives + False Positives)\n",
    "\n",
    "= 100 / (100 + 10) = 0.91"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall (Sensitivity or True Positive Rate)\n",
    "\n",
    "**Recall** is the ratio of correctly predicted positive (TP) observations to all actual positives (TP + FN). It is defined as:\n",
    "\n",
    "Recall = True Positives / (True Positives + False Negatives)\n",
    "\n",
    "= 100 / (100 + 5) = 0.95"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1 Score\n",
    "\n",
    "**F1 Score** is the weighted average of Precision and Recall. Therefore, this score takes both false positives and false negatives into account. It's defined as:\n",
    "\n",
    "F1 Score = 2*(Recall * Precision) / (Recall + Precision)\n",
    "\n",
    "= 2 * (0.95 * 0.91) / (0.95 + 0.91) = 0.93"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
